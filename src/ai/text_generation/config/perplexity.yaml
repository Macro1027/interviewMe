# Perplexity API Configuration

# API endpoint
api_url: "https://api.perplexity.ai/chat/completions"

# Default model to use
default_model: "pplx-70b-online"

# Available models
available_models:
  - "pplx-7b-online"
  - "pplx-70b-online"
  - "pplx-7b-chat"
  - "pplx-70b-chat"
  - "llama-2-70b-chat"
  - "mistral-7b-instruct"
  - "mixtral-8x7b-instruct"

# Retry configuration
max_retries: 3
retry_delay_seconds: 1
retry_backoff_factor: 2

# Rate limiting
requests_per_minute: 50

# Default generation parameters
default_params:
  temperature: 0.7
  max_tokens: 1000
  top_p: 0.9
  presence_penalty: 0.0
  frequency_penalty: 0.0 