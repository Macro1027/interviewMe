# Hugging Face API Configuration

# API endpoint (base URL)
api_url: "https://api-inference.huggingface.co/models/"

# Default model to use
default_model: "mistralai/Mixtral-8x7B-Instruct-v0.1"

# Available models
available_models:
  - "mistralai/Mixtral-8x7B-Instruct-v0.1"
  - "meta-llama/Llama-2-70b-chat-hf"
  - "meta-llama/Llama-2-13b-chat-hf"
  - "meta-llama/Llama-2-7b-chat-hf"
  - "mistralai/Mistral-7B-Instruct-v0.1"
  - "tiiuae/falcon-7b-instruct"
  - "tiiuae/falcon-40b-instruct"

# Retry configuration
max_retries: 3
retry_delay_seconds: 1
retry_backoff_factor: 2

# Default generation parameters
default_params:
  temperature: 0.7
  max_new_tokens: 1000
  top_p: 0.95
  top_k: 50
  repetition_penalty: 1.1
  do_sample: true
  return_full_text: false

# Format settings
chat_template:
  system_prefix: "<|system|>"
  user_prefix: "<|user|>"
  assistant_prefix: "<|assistant|>"
  end_token: "</s>" 